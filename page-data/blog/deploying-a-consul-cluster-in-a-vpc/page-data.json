{"componentChunkName":"component---src-pages-markdown-remark-frontmatter-slug-js","path":"/blog/deploying-a-consul-cluster-in-a-vpc/","result":{"data":{"markdownRemark":{"html":"<p>In this article I'd like to show you how you might deploy a Consul cluster into a <a href=\"http://aws.amazon.com/vpc/\">Amazon Virtual Private Cloud</a> using a few of my favorite tools: <a href=\"https://github.com/cloudtools/troposphere\">Troposphere</a>, <a href=\"http://aws.amazon.com/cloudformation/\">CloudFormation</a> and <a href=\"http://www.ansible.com/home\">Ansible</a>. There's also a little <a href=\"http://www.thekelleys.org.uk/dnsmasq/doc.html\">Dnsmasq</a> thrown in for good measure.</p>\n<p>To support this article I have created a <a href=\"https://www.github.com/mattupstate/vpc-consul\">repository</a> with the relevant files you will need to deploy this on your own.</p>\n<blockquote>\n<p><strong>Update</strong><br>\nI originally wrote this article on June 9th and Consul was only at version 2.1. I've since updated the article and code on September 2nd, 2014 to take advantage of some new features on Consul 3.1.</p>\n</blockquote>\n<h2>Components</h2>\n<h3>Consul</h3>\n<p>But first, why would you want to do this? Well, because Consul is pretty awesome. I won't go into <a href=\"http://www.consul.io/intro/index.html\">all the reasons Consul is awesome</a>, but lets just say it's got many features one might want for their infrastructure, especially when you have various services coming and going throughout various times of the day, week, month, etc.</p>\n<h3>The VPC</h3>\n<p>Before you deploy a VPC you're going to want to consider much about its design. There is a lot to consider when it comes to this and there's never a one size fits all model. That being said, I've designed the VPC for this article in what I believe to be a generic fashion in hopes that its easy for you to extend and/or modify.</p>\n<p>The VPC is arguably designed with high availability in mind. This is achieved by distributing a public and private subnet across three availability zones. Each public subnet is meant to contain load balancers, proxies, etc. Where as each private subnet is meant to contain application servers, databases, message queues, etc. Additionally, each private subnet contains one instance meant to act as a Consul server. The idea is that if a network partition occurs between one AZ, the cluster should continue to operate until the AZ comes back online. Lastly, there is one bastion host that will be located in the first public subnet to allow SSH access to servers within the VPC.</p>\n<h3>CloudFormation and Troposphere</h3>\n<p>There are a lot of components that need to be wired together when deploying a VPC. It is without a doubt that doing this for a VPC with any complexity is a complete drag of a task when doing it through the AWS management console. This is where CloudFormation comes in. Gone are the days of fumbling through all the UI screens and in are the days of abstracting your AWS resources through a declarative templating format! Seriously, if you're not using CloudFormation, get to it.</p>\n<p>There is one annoying thing about CloudFormation though, and thats the templates. They're kind of annoying to write by hand. However, there are a plethora of tools out there to help you write your templates. <a href=\"https://github.com/cloudtools/troposphere\">Troposphere</a> happens to be my favorite tool, mostly because its written in Python. You can see <a href=\"https://github.com/mattupstate/vpc-consul/blob/master/template.py\">here</a> how I've used Troposphere to create the <a href=\"https://github.com/mattupstate/vpc-consul/blob/master/template.json\">CloudFormation template</a> for the VPC.</p>\n<h3>Ansible</h3>\n<p>While CloudFormation is great, I still find myself leaving provisioning to another tool rather than leveraging the tools built into AWS. So rather than abstract provisioning in the stack template, I've opted to use <a href=\"http://www.ansible.com/home\">Ansible</a> to get the bastion and Consul servers up and running. The main thing to mention is the <a href=\"https://github.com/mattupstate/vpc-consul/blob/master/hosts\">custom inventory script</a> thats been tailored for this article. Notice that the host IP addresses have been hardcoded to the <a href=\"https://github.com/mattupstate/vpc-consul/blob/master/template.py#L258\">values specified in the CloudFormation template</a>.</p>\n<h3>Dnsmasq</h3>\n<p>The last piece of the puzzle is to use <a href=\"http://www.thekelleys.org.uk/dnsmasq/doc.html\">Dnsmasq</a> to foward DNS queries to any Consul hostnames to the local agent. This is very easy to do and is <a href=\"https://github.com/mattupstate/vpc-consul/blob/master/provision_consul.yaml#L53-L60\">illustrated in the Consul server provisioning playbook</a>.</p>\n<h2>Deployment</h2>\n<p>Time to deploy! Follow these steps:</p>\n<h5>1. Install Ansible on your local machine</h5>\n<p>Please refer to the Ansible docs for <a href=\"http://docs.ansible.com/intro_installation.html\">how to install</a> to your local machine.</p>\n<h5>2. Create the stack</h5>\n<p>Create a CloudFormation stack using <a href=\"https://github.com/mattupstate/vpc-consul/blob/master/template.json\">template.json</a> via the AWS managment console or the API. When asked for the parameters be sure to enter the appropriate availability zone letters. The zones in which you can deploy subnets into is dependent on your AWS account. The deafult is <code class=\"language-text\">a,b,e</code> because that is what my account required. Additionally, remember to enter a value key pair name so that you can ssh into the bastion and Consul servers.</p>\n<h5>3. Provision the bastion</h5>\n<p>The bastion will need to be provisioned in order to manage the Consul servers. First, get the bastion IP address from the stack's outputs and set the <code class=\"language-text\">BASTION_HOST_IP</code> environment variable:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">git</span> clone https://github.com/mattupstate/vpc-consul.git <span class=\"token operator\">&amp;&amp;</span> <span class=\"token builtin class-name\">cd</span> vpc-consul\nssh-add <span class=\"token operator\">&lt;</span>/path/to/keypair.pem<span class=\"token operator\">></span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">BASTION_HOST_IP</span><span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>bastion-ip-output-from-stack<span class=\"token operator\">></span>\nansible-playbook <span class=\"token parameter variable\">-i</span> hosts provision_bastion.yaml</code></pre></div>\n<h5>4. Provision the Consul servers</h5>\n<p>SSH into the bastion and provision the Consul servers. Turning on SSH agent forwarding is highly recommended.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">ssh</span> ubuntu@<span class=\"token variable\">$BASTION_HOST_IP</span> <span class=\"token parameter variable\">-o</span> <span class=\"token assign-left variable\">ForwardAgent</span><span class=\"token operator\">=</span>yes\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">ANSIBLE_HOST_KEY_CHECKING</span><span class=\"token operator\">=</span>False\nansible-playbook <span class=\"token parameter variable\">-i</span> hosts provision_consul.yaml</code></pre></div>\n<h5>5. Verify the cluster</h5>\n<p>Now you'll want to SSH into one of the Consul servers and be sure that the cluster is in the desired state. The output should look like the following:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">ssh</span> <span class=\"token number\">10.0</span>.16.4\nconsul members\nNode                     Address         Status  Type    Build  Protocol\nconsul-server-10-0-16-4  <span class=\"token number\">10.0</span>.16.4:8301  alive   server  <span class=\"token number\">0.3</span>.1  <span class=\"token number\">2</span>\nconsul-server-10-0-32-4  <span class=\"token number\">10.0</span>.32.4:8301  alive   server  <span class=\"token number\">0.3</span>.1  <span class=\"token number\">2</span>\nconsul-server-10-0-48-4  <span class=\"token number\">10.0</span>.48.4:8301  alive   server  <span class=\"token number\">0.3</span>.1  <span class=\"token number\">2</span></code></pre></div>\n<h5>6. Verify DNS lookups</h5>\n<p>Check that Dnsmasq is successfully forwarding DNS queries to Consul. The output should look like the following:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">dig</span> consul-server-10-0-32-4.node.consul\n\n<span class=\"token punctuation\">;</span> <span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">>></span> DiG <span class=\"token number\">9.9</span>.5-3-Ubuntu <span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">>></span> consul-server-10-0-32-4.node.consul\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> global options: +cmd\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> Got answer:\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> -<span class=\"token operator\">>></span>HEADER<span class=\"token operator\">&lt;&lt;-</span> opcode: QUERY, status: NOERROR, id: <span class=\"token number\">59853</span>\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> flags: qr aa rd ra<span class=\"token punctuation\">;</span> QUERY: <span class=\"token number\">1</span>, ANSWER: <span class=\"token number\">1</span>, AUTHORITY: <span class=\"token number\">0</span>, ADDITIONAL: <span class=\"token number\">0</span>\n\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> QUESTION SECTION:\n<span class=\"token punctuation\">;</span>consul-server-10-0-32-4.node.consul. IN    A\n\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> ANSWER SECTION:\nconsul-server-10-0-32-4.node.consul. <span class=\"token number\">0</span> IN A <span class=\"token number\">10.0</span>.32.4\n\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> Query time: <span class=\"token number\">5</span> msec\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> SERVER: <span class=\"token number\">127.0</span>.0.1<span class=\"token comment\">#53(127.0.0.1)</span>\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> WHEN: Mon Jun 09 <span class=\"token number\">16</span>:55:30 UTC <span class=\"token number\">2014</span>\n<span class=\"token punctuation\">;</span><span class=\"token punctuation\">;</span> MSG SIZE  rcvd: <span class=\"token number\">104</span></code></pre></div>\n<h2>Wrap Up</h2>\n<p>So there you have it. A perfectly working three node Consul cluster distributed across three availability zones, each in a private subnet protected from the outside world. Now when you deploy any new instances into your VPC you'll want to make sure that you install and run the Consul agent, optionally registering any services made available by those instances. Also consider registering various health checks for the instance and services.</p>\n<p>If anyone has any ideas on how to improve this please comment below. Thanks for reading!</p>","frontmatter":{"date":"June 10, 2014","slug":"/blog/deploying-a-consul-cluster-in-a-vpc","title":"Deploying a Consul cluster in a VPC","description":null}},"metaImageFile":{"relativePath":"images/headshot-summary.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#583828","images":{"fallback":{"src":"/static/9798db320c5cad183af92ab85933ac64/38397/headshot-summary.png","srcSet":"/static/9798db320c5cad183af92ab85933ac64/cef30/headshot-summary.png 531w,\n/static/9798db320c5cad183af92ab85933ac64/d6f8b/headshot-summary.png 1061w,\n/static/9798db320c5cad183af92ab85933ac64/38397/headshot-summary.png 2122w","sizes":"(min-width: 2122px) 2122px, 100vw"},"sources":[{"srcSet":"/static/9798db320c5cad183af92ab85933ac64/45ee3/headshot-summary.webp 531w,\n/static/9798db320c5cad183af92ab85933ac64/af37a/headshot-summary.webp 1061w,\n/static/9798db320c5cad183af92ab85933ac64/c2899/headshot-summary.webp 2122w","type":"image/webp","sizes":"(min-width: 2122px) 2122px, 100vw"}]},"width":2122,"height":1070}}}},"pageContext":{"id":"b6afcadd-7ac7-5ea8-9a5f-e948a7d73acb","frontmatter__slug":"/blog/deploying-a-consul-cluster-in-a-vpc","__params":{"frontmatter__slug":"blog"}}},"staticQueryHashes":["2052298874"]}